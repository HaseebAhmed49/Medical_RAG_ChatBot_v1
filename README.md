# ğŸ“š Medical RAG ChatBot v1 Documentation

Welcome to the Medical RAG ChatBot v1! This project processes **PDF documents, generates embeddings using HuggingFace models, and stores them in a FAISS vector database** for efficient retrieval-based tasks. It also allows querying the vector database to retrieve relevant information. ğŸš€

![image](https://github.com/user-attachments/assets/3eaf235d-eedc-4262-a089-210dff769073)

---

## ğŸŒŸğŸš€ Features
âœ… **Load PDFs** - The application loads all PDF files from the data directory using the DirectoryLoader.

âœ… **Split PDFs into Chunks** - PDFs are split into smaller chunks of 500 characters with a 50-character overlap for better embedding generation.

âœ… **Generate Embeddings** - Embeddings are generated using the HuggingFace model: sentence-transformers/all-MiniLM-L6-v2.

âœ… **Store in FAISS Vector Database** - The embeddings are stored in a FAISS vector database for efficient retrieval.

âœ… **Query the Vector Database** - Users can query the vector database with natural language questions to retrieve relevant information.

---

## Project Structure
```sh
ğŸ“‚ Medical_RAG_ChatBot_v1/
â”œâ”€â”€ ğŸ“‚ backend/
â”‚   â””â”€â”€ main.py          # FastAPI backend for processing and querying embeddings
â”œâ”€â”€ ğŸ“‚ data/             # Directory for storing PDF files
â”œâ”€â”€ ğŸ“‚ vectorstore/
â”‚   â””â”€â”€ db_faiss/        # FAISS vector database files
â”œâ”€â”€ Pipfile              # Dependency management
â”œâ”€â”€ Pipfile.lock         # Locked dependencies
â””â”€â”€ .env                 # Environment variables (optional)
```

---

## Technologies Used
* **Python** Programming Language
* **LangChain** for AI Framework for LLM Applications
* **HuggingFace** AI/ML Hub
* **Mistral** LLM Model
* **FAISS** Vector Database
* **FastAPI** for backend API
* **Streamlit** for ChatBot UI
* **VS Code** (IDE)

---

## âš™ï¸ Setup Guide
Follow these steps to set up the project on your local machine:

1ï¸âƒ£ Prerequisites
- ğŸ Python 3.8 or higher
- ğŸ“¦ Pipenv for dependency management
- ğŸ’¾ FAISS installed (faiss-cpu)

2ï¸âƒ£ Clone the Repository
```sh
git clone <repository-url>
cd Medical_RAG_ChatBot_v1
```

3ï¸âƒ£ Install Dependencies
```sh
pipenv install
```

4ï¸âƒ£ Activate the Virtual Environment
```sh
pipenv shell
```

5ï¸âƒ£ Add PDF Files
- Place your PDF files in the data directory.

6ï¸âƒ£ (Optional) Configure Environment Variables
- Create a .env file in the root directory to store HuggingFace API Token as environment variables.

---

## â–¶ï¸ How to Run the Application

### ğŸ“Œ Backend Start the FastAPI Server
1ï¸âƒ£ Start the FastAPI Server
Run the following command to start the server:
```sh
uvicorn backend.main:app --reload
```
The server will be available at: http://127.0.0.1:8000

2ï¸âƒ£ Use the API Endpoints
The application provides two endpoints for interacting with the vector database:

### ğŸ› ï¸ API Endpoints
1ï¸âƒ£ POST **/store_embeddings_in_db**
- **Description**: Processes PDF files, generates embeddings for text chunks, and stores them in a FAISS vector database.
- **Steps**:
  1. Load PDF files from the data directory.
  2. Split the PDF content into smaller chunks (500 characters with a 50-character overlap).
  3. Generate embeddings using the HuggingFace model: **sentence-transformers/all-MiniLM-L6-v2**.
  4. Store the embeddings in a FAISS vector database located at db_faiss.
- **Response**:
  * **200 OK**: Embeddings successfully stored.
  * **400 Bad Request**: Missing files or invalid data.
  * **500 Internal Server Error**: Unexpected error.

2ï¸âƒ£ GET **/query/{question}**
- **Description**: Queries the FAISS vector database with a user-provided question and retrieves relevant information.
- **Steps**:
  1. Load the FAISS vector database and the HuggingFace embedding model.
  2. Use a custom prompt template to structure the query.
  3. Retrieve relevant chunks from the vector database.
  4. Use a language model (e.g., Mistral-7B) to generate an answer based on the retrieved chunks.
- **Path Parameter**:
  * question (string): The question to query the vector database.
- **Response**:
  * **200 OK**: Returns the answer to the query.
  * **404 Not Found**: If no relevant data is found.
  * **500 Internal Server Error**: Unexpected error.

## ğŸ¨ Frontend (Streamlit)

### ğŸ“Œ Run the Streamlit App
```sh
streamlit run frontend/app.py
```

---

## ğŸš€ Future Enhancements
- Add more advanced query capabilities (e.g., multi-document summarization).
- Implement user authentication for API endpoints.
- Support additional document formats (e.g., Word, Excel).

---

## ğŸ“œ License
This project is licensed under the MIT License.

---

## ğŸ“© Contact
For issues or suggestions, feel free to open an [issue](https://github.com/HaseebAhmed49/Medical_RAG_ChatBot_v1/issues) or reach out!
* Email: haseebahmed02@gmail.com
* LinkedIn/GitHub: /HaseebAhmed49

ğŸ’¡ **Happy Coding!** ğŸš€
